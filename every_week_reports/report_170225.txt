Отчет номер 2.
За неделю читал только статьи. Концентрировался на поиске всего, что хоть как-то можно пригодиться.
Прочел:
- A Genetic Algorithm for Automatic Feature Extraction in P300 Detection. Классическая статья по генерации признаков генетическим алгоритмом. Единственная, в которой вместо KNN стоит Logistec Regression. Оценка качества признака - точность на 4 фолдовой CV
- Automatic Feature Extraction and Image Classification Using Genetic Programming. Тоже самое, но только длоя картинок, сделанная до того, как поняли, что CNN всех в этом теме победит. Чем хороша: тут явно дополнительно прописывается структура признака (это уже не совсем признак, а маленький алгоритм). Сначала мы изображение фильтруем, дажее применяем какую-то аргрегирующую функцию, а затем выыходы складываем, вычитаем, делим и смотрим на выход структуры. Если > 0, то это класс 1, иначе класс 0. Метрика качества - просто точность выхода такой схемы.
- Automatic feature extraction using genetic programming: An application to epileptic EEG classification. Чем хороша: тут немного другой подход к сигналам. Сначала делается стандартная любимая всеми нами табличка, с помощью вейвлет-преобразования, из которого извлекаются 5 суб сигналов, к которым применяют 5 агрегирующих функций (типо mean, std, etc). Далее натриавливается классический генетический алгоритм, но уже с возможностью слкадывать, вычитать, брать логарифм и так далее от столбцов матрицы. Качество признака: скор KNN на hold out валидации
- AutoCompete: A Framework for Machine Learning Competitions. Это скорее для общего развития. Описан челендж по созданию автонюнящийся машины ииз смеси различных классификаторов, мечта для покорителей Кагла. Мое уважение авторам, но ничего дельного или полезного я здесь не нашел. Но штука забавная
- Feature Selection for High-Dimensional Data: A Fast Correlation-Based Filter Solution. Предельно приятная статья про то как мерить качество признаков помимо как "запихнуть в классифкатор и посомтреть метрику". Сам алгоритм фильтрации мне не нужен, но основной мессендж хороший. МОэно смотреть линейную зависимость от таргета (корреляцию), а можно не линейную (энтропию). Хорошая мысль в том, что если у нас признак имеет высокий показательно какого-либо критерия от таргета, это еще не значит, что он хороший, взможно он просто сильно связан с другими нашими признаками и избыточен, так что нам нужны признаки, которые связаны с таргетом сильнее, чем с любым другим имеющимся признаком. Это норм посыл для оценки качества признака, я считаю.
- Evolving Neural Networks through Augmenting Topologies. Класическая статья 2002 года про нейроэволюцию. Всю не осилил, но идея простая: тюнить веса нейронки нам мало, будет тюнить саму ее топологию. Как будем тюнить? Генетический алгоритмом. Полезна нам тем, что мы можем настраивать не только преобразования из одной сигнала 1 -> сигнал2 -> ...чиселка, а еще как-то их комбинировать, и саму топологию графа тоже настраивать каким-либо методом оптимизации. 
+ прочитал несколько статей с сайта http://automl.chalearn.org/ , но ничего примечательного я в них не нашел, так что сюда я иъ не включил

В итоге я прочитал довольно много букв за неделю, так что морально и интеллектуально я готов кодить.

